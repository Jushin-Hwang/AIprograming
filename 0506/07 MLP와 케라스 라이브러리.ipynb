{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니 배치 실습 #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터는 텐서플로우 안에 내장된 숫자 필기체 이미지 데이터이다.\n",
    "# 약 6만개의 이미지가 저장되어 있다.\n",
    "# NMIST 데이터에서 12개의 샘플을 무작위로 뽑는 코드를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30561 31520 52759 23025 59166 49200 53162 44332 54291  7303 49175 12911]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터를 학습 데이터와 테스트 데이터로 나눈다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "data_size = x_train.shape[0]\n",
    "batch_size = 12 # 배치 크기\n",
    "\n",
    "selected = np.random.choice(data_size, batch_size)\n",
    "print(selected)\n",
    "x_batch = x_train[selected]\n",
    "y_batch = y_train[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(t, y) :\n",
    "    size = y.shape[0]\n",
    "    return 0.5 * np.sum((y-t) ** 2) / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니 배치의 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]] [0] [[0.01539626]]\n",
      "[[0 1]] [1] [[0.98676414]]\n",
      "[[1 0]] [1] [[0.98677556]]\n",
      "[[1 1]] [0] [[0.01366182]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 시그모이드 함수 구현\n",
    "def sigmoid(x) :\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# 시그모이드 함수의 미분치\n",
    "def sigmoid_deriv(x) :\n",
    "    return x * (1-x)\n",
    "\n",
    "# 입력 유닛의 개수, 은닉 유닛의 개수, 출력 유닛의 개수\n",
    "inputs, hiddens, outputs = 2, 2, 1\n",
    "learning_rate = 0.5\n",
    "\n",
    "# 훈련 샘플과 정답\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "T = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# 가중치를 -1.0에서 1.0 사이의 난수로 초기화한다.\n",
    "W1 = 2 * np.random.random((inputs, hiddens)) - 1\n",
    "W2 = 2 * np.random.random((hiddens, outputs)) - 1\n",
    "B1 = np.zeros(hiddens)\n",
    "B2 = np.zeros(outputs)\n",
    "\n",
    "# 순방향 전파 계산\n",
    "def predict(x) :\n",
    "    layer0 = x\n",
    "    Z1 = np.dot(layer0, W1) + B1\n",
    "    layer1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(layer1, W2) + B2\n",
    "    layer2 = sigmoid(Z2)\n",
    "    return layer0, layer1, layer2\n",
    "\n",
    "# 역방향 전파 계산\n",
    "def fit() :\n",
    "    global W1, W2, B1, B2\n",
    "    for i in range(60000) :\n",
    "        layer0, layer1, layer2 = predict(X)\n",
    "        layer2_error = layer2 - T\n",
    "\n",
    "        layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "        layer1_error = np.dot(layer2_delta, W2.T)\n",
    "        layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "\n",
    "        W2 += -learning_rate * np.dot(layer1.T, layer2_delta) / 4.0\n",
    "        W1 += -learning_rate * np.dot(layer0.T, layer1_delta) / 4.0\n",
    "        B2 += -learning_rate * np.sum(layer2_delta, axis = 0) / 4.0\n",
    "        B1 += -learning_rate * np.sum(layer1_delta, axis = 0) / 4.0\n",
    "\n",
    "def test() :\n",
    "    for x, y in zip(X, T) :\n",
    "        x = np.reshape(x, (1, -1))\n",
    "        layer0, layer1, layer2 = predict(x)\n",
    "        print(x, y, layer2)\n",
    "\n",
    "fit()\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR를 학습하는 MLP 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\황주신\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units = 2, input_shape = (2,), activation = 'sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = tf.keras.optimizers.SGD(learning_rate = 0.3))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2545  \n",
      "Epoch 2/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2370 \n",
      "Epoch 3/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2559 \n",
      "Epoch 4/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2577 \n",
      "Epoch 5/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2642 \n",
      "Epoch 6/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2543 \n",
      "Epoch 7/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2590 \n",
      "Epoch 8/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 9/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2504 \n",
      "Epoch 10/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2534 \n",
      "Epoch 11/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2567 \n",
      "Epoch 12/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2620 \n",
      "Epoch 13/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 14/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2568 \n",
      "Epoch 15/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2559 \n",
      "Epoch 16/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2616 \n",
      "Epoch 17/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2563 \n",
      "Epoch 18/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2582 \n",
      "Epoch 19/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 20/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2613 \n",
      "Epoch 21/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2616 \n",
      "Epoch 22/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2608 \n",
      "Epoch 23/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2530 \n",
      "Epoch 24/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2610 \n",
      "Epoch 25/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2560 \n",
      "Epoch 26/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2504 \n",
      "Epoch 27/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2608 \n",
      "Epoch 28/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 29/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2613 \n",
      "Epoch 30/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2623 \n",
      "Epoch 31/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2582 \n",
      "Epoch 32/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2581 \n",
      "Epoch 33/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2610 \n",
      "Epoch 34/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2578 \n",
      "Epoch 35/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2605 \n",
      "Epoch 36/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2610 \n",
      "Epoch 37/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 38/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 39/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2558 \n",
      "Epoch 40/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2608 \n",
      "Epoch 41/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2625 \n",
      "Epoch 42/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2572 \n",
      "Epoch 43/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2598 \n",
      "Epoch 44/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2550 \n",
      "Epoch 45/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2569 \n",
      "Epoch 46/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2501 \n",
      "Epoch 47/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2610 \n",
      "Epoch 48/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2543 \n",
      "Epoch 49/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2536 \n",
      "Epoch 50/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2605 \n",
      "Epoch 51/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2545 \n",
      "Epoch 52/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 53/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2551 \n",
      "Epoch 54/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2604 \n",
      "Epoch 55/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 56/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 57/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2604 \n",
      "Epoch 58/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2615 \n",
      "Epoch 59/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2588 \n",
      "Epoch 60/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 61/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2505 \n",
      "Epoch 62/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2541 \n",
      "Epoch 63/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 64/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2496 \n",
      "Epoch 65/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 66/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2538 \n",
      "Epoch 67/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2596 \n",
      "Epoch 68/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2542 \n",
      "Epoch 69/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 70/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2589 \n",
      "Epoch 71/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 72/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 73/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 74/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2621 \n",
      "Epoch 75/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2588 \n",
      "Epoch 76/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2542 \n",
      "Epoch 77/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2585 \n",
      "Epoch 78/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2625 \n",
      "Epoch 79/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2594 \n",
      "Epoch 80/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2629 \n",
      "Epoch 81/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 82/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2621 \n",
      "Epoch 83/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2620 \n",
      "Epoch 84/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2564 \n",
      "Epoch 85/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2521 \n",
      "Epoch 86/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2536 \n",
      "Epoch 87/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2623 \n",
      "Epoch 88/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2625 \n",
      "Epoch 89/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2598 \n",
      "Epoch 90/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 91/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 92/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2520 \n",
      "Epoch 93/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2600 \n",
      "Epoch 94/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2538 \n",
      "Epoch 95/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2525 \n",
      "Epoch 96/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 97/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2589 \n",
      "Epoch 98/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 99/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2542 \n",
      "Epoch 100/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2621 \n",
      "Epoch 101/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2611 \n",
      "Epoch 102/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2569 \n",
      "Epoch 103/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2607 \n",
      "Epoch 104/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2556 \n",
      "Epoch 105/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2584 \n",
      "Epoch 106/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2606 \n",
      "Epoch 107/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2589 \n",
      "Epoch 108/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 109/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2562 \n",
      "Epoch 110/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 111/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2543 \n",
      "Epoch 112/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2609 \n",
      "Epoch 113/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2596 \n",
      "Epoch 114/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2566 \n",
      "Epoch 115/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2591 \n",
      "Epoch 116/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2596 \n",
      "Epoch 117/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2605 \n",
      "Epoch 118/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2560 \n",
      "Epoch 119/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 120/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2633 \n",
      "Epoch 121/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2503 \n",
      "Epoch 122/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2533 \n",
      "Epoch 123/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2539 \n",
      "Epoch 124/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2596 \n",
      "Epoch 125/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2571 \n",
      "Epoch 126/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2618 \n",
      "Epoch 127/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 128/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2597 \n",
      "Epoch 129/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2566 \n",
      "Epoch 130/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2608 \n",
      "Epoch 131/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 132/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2598 \n",
      "Epoch 133/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2505 \n",
      "Epoch 134/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2583 \n",
      "Epoch 135/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2590 \n",
      "Epoch 136/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 137/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2532 \n",
      "Epoch 138/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 139/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 140/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2633 \n",
      "Epoch 141/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 142/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2493 \n",
      "Epoch 143/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 144/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2623 \n",
      "Epoch 145/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2522 \n",
      "Epoch 146/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2551 \n",
      "Epoch 147/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2619 \n",
      "Epoch 148/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2590 \n",
      "Epoch 149/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 150/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2530 \n",
      "Epoch 151/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2607 \n",
      "Epoch 152/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2593 \n",
      "Epoch 153/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2569 \n",
      "Epoch 154/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 155/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 156/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2537 \n",
      "Epoch 157/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 158/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 159/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 160/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2613 \n",
      "Epoch 161/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2611 \n",
      "Epoch 162/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2616 \n",
      "Epoch 163/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 164/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2558 \n",
      "Epoch 165/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2592 \n",
      "Epoch 166/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 167/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2571 \n",
      "Epoch 168/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2575 \n",
      "Epoch 169/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2583 \n",
      "Epoch 170/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2622 \n",
      "Epoch 171/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 172/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2619 \n",
      "Epoch 173/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 174/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2595 \n",
      "Epoch 175/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2564 \n",
      "Epoch 176/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 177/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 178/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2533 \n",
      "Epoch 179/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 180/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 181/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2553 \n",
      "Epoch 182/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2621 \n",
      "Epoch 183/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2620 \n",
      "Epoch 184/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2618 \n",
      "Epoch 185/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2594 \n",
      "Epoch 186/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2584 \n",
      "Epoch 187/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 188/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 189/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2612 \n",
      "Epoch 190/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2568 \n",
      "Epoch 191/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2621 \n",
      "Epoch 192/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 193/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2565 \n",
      "Epoch 194/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2500 \n",
      "Epoch 195/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2518 \n",
      "Epoch 196/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2604 \n",
      "Epoch 197/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2561 \n",
      "Epoch 198/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2606 \n",
      "Epoch 199/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 200/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2563 \n",
      "Epoch 201/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2603 \n",
      "Epoch 202/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 203/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2604 \n",
      "Epoch 204/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2571 \n",
      "Epoch 205/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2610 \n",
      "Epoch 206/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 207/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2595 \n",
      "Epoch 208/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2568 \n",
      "Epoch 209/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2559 \n",
      "Epoch 210/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2527 \n",
      "Epoch 211/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2588 \n",
      "Epoch 212/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2536 \n",
      "Epoch 213/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2531 \n",
      "Epoch 214/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2533 \n",
      "Epoch 215/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2569 \n",
      "Epoch 216/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2518 \n",
      "Epoch 217/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2583 \n",
      "Epoch 218/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2584 \n",
      "Epoch 219/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2613 \n",
      "Epoch 220/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2615 \n",
      "Epoch 221/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 222/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 223/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2543 \n",
      "Epoch 224/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2531 \n",
      "Epoch 225/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2609 \n",
      "Epoch 226/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2536 \n",
      "Epoch 227/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 228/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2606 \n",
      "Epoch 229/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2589 \n",
      "Epoch 230/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2604 \n",
      "Epoch 231/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2594 \n",
      "Epoch 232/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2584 \n",
      "Epoch 233/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 234/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 235/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2588 \n",
      "Epoch 236/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2558 \n",
      "Epoch 237/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2606 \n",
      "Epoch 238/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2526 \n",
      "Epoch 239/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2573 \n",
      "Epoch 240/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2604 \n",
      "Epoch 241/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2603 \n",
      "Epoch 242/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 243/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2551 \n",
      "Epoch 244/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 245/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2570 \n",
      "Epoch 246/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 247/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 248/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 249/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2536 \n",
      "Epoch 250/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2517 \n",
      "Epoch 251/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2608 \n",
      "Epoch 252/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 253/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2605 \n",
      "Epoch 254/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2561 \n",
      "Epoch 255/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2617 \n",
      "Epoch 256/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 257/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2612 \n",
      "Epoch 258/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 259/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2591 \n",
      "Epoch 260/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 261/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 262/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2567 \n",
      "Epoch 263/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2523 \n",
      "Epoch 264/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 265/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2553 \n",
      "Epoch 266/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2555 \n",
      "Epoch 267/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2507 \n",
      "Epoch 268/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2585 \n",
      "Epoch 269/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 270/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2528 \n",
      "Epoch 271/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2594 \n",
      "Epoch 272/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2542 \n",
      "Epoch 273/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2529 \n",
      "Epoch 274/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2526 \n",
      "Epoch 275/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2610 \n",
      "Epoch 276/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2589 \n",
      "Epoch 277/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2558 \n",
      "Epoch 278/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 279/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 280/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2498 \n",
      "Epoch 281/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2583 \n",
      "Epoch 282/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 283/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2608 \n",
      "Epoch 284/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2607 \n",
      "Epoch 285/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2598 \n",
      "Epoch 286/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 287/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2594 \n",
      "Epoch 288/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2602 \n",
      "Epoch 289/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2602 \n",
      "Epoch 290/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2587 \n",
      "Epoch 291/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2554 \n",
      "Epoch 292/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 293/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2521 \n",
      "Epoch 294/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2529 \n",
      "Epoch 295/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 296/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2609 \n",
      "Epoch 297/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2590 \n",
      "Epoch 298/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 299/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2539 \n",
      "Epoch 300/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 301/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2519 \n",
      "Epoch 302/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2579 \n",
      "Epoch 303/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 304/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2541 \n",
      "Epoch 305/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2510 \n",
      "Epoch 306/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 307/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2545 \n",
      "Epoch 308/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 309/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2537 \n",
      "Epoch 310/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 311/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2556 \n",
      "Epoch 312/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2522 \n",
      "Epoch 313/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 314/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2598 \n",
      "Epoch 315/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2588 \n",
      "Epoch 316/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2585 \n",
      "Epoch 317/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 318/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 319/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2579 \n",
      "Epoch 320/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2607 \n",
      "Epoch 321/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 322/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2574 \n",
      "Epoch 323/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2534 \n",
      "Epoch 324/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2609 \n",
      "Epoch 325/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 326/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 327/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2518 \n",
      "Epoch 328/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2597 \n",
      "Epoch 329/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2529 \n",
      "Epoch 330/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2525 \n",
      "Epoch 331/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 332/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2579 \n",
      "Epoch 333/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2585 \n",
      "Epoch 334/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 335/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2541 \n",
      "Epoch 336/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2522 \n",
      "Epoch 337/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2602 \n",
      "Epoch 338/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2535 \n",
      "Epoch 339/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2599 \n",
      "Epoch 340/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2592 \n",
      "Epoch 341/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 342/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 343/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2599 \n",
      "Epoch 344/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2546 \n",
      "Epoch 345/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2509 \n",
      "Epoch 346/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2589 \n",
      "Epoch 347/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2531 \n",
      "Epoch 348/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2568 \n",
      "Epoch 349/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2576 \n",
      "Epoch 350/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2526 \n",
      "Epoch 351/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 352/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2603 \n",
      "Epoch 353/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2573 \n",
      "Epoch 354/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 355/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2586 \n",
      "Epoch 356/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2534 \n",
      "Epoch 357/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 358/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2609 \n",
      "Epoch 359/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2590 \n",
      "Epoch 360/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2614 \n",
      "Epoch 361/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2619 \n",
      "Epoch 362/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2598 \n",
      "Epoch 363/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2510 \n",
      "Epoch 364/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2569 \n",
      "Epoch 365/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 366/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 367/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2537 \n",
      "Epoch 368/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2584 \n",
      "Epoch 369/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2590 \n",
      "Epoch 370/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 371/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2605 \n",
      "Epoch 372/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2527 \n",
      "Epoch 373/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2532 \n",
      "Epoch 374/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 375/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2558 \n",
      "Epoch 376/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 377/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2580 \n",
      "Epoch 378/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2581  \n",
      "Epoch 379/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2583 \n",
      "Epoch 380/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2536 \n",
      "Epoch 381/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2606 \n",
      "Epoch 382/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 383/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2601 \n",
      "Epoch 384/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2511 \n",
      "Epoch 385/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2579 \n",
      "Epoch 386/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 387/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 388/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2601 \n",
      "Epoch 389/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2584 \n",
      "Epoch 390/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2584 \n",
      "Epoch 391/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2550 \n",
      "Epoch 392/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2588 \n",
      "Epoch 393/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2605 \n",
      "Epoch 394/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2582 \n",
      "Epoch 395/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2575 \n",
      "Epoch 396/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2538 \n",
      "Epoch 397/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2570 \n",
      "Epoch 398/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 399/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2574 \n",
      "Epoch 400/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2549  \n",
      "Epoch 401/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2567 \n",
      "Epoch 402/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2506 \n",
      "Epoch 403/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2577 \n",
      "Epoch 404/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2545 \n",
      "Epoch 405/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2585 \n",
      "Epoch 406/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 407/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2520 \n",
      "Epoch 408/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2579 \n",
      "Epoch 409/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 410/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2555 \n",
      "Epoch 411/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2514 \n",
      "Epoch 412/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2574 \n",
      "Epoch 413/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2571 \n",
      "Epoch 414/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2539 \n",
      "Epoch 415/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 416/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2603 \n",
      "Epoch 417/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2560 \n",
      "Epoch 418/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2616 \n",
      "Epoch 419/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2506 \n",
      "Epoch 420/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 421/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 422/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2533 \n",
      "Epoch 423/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 424/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2547 \n",
      "Epoch 425/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 426/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2581 \n",
      "Epoch 427/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2538 \n",
      "Epoch 428/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2610 \n",
      "Epoch 429/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2519 \n",
      "Epoch 430/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 431/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 432/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2596 \n",
      "Epoch 433/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2522 \n",
      "Epoch 434/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2548 \n",
      "Epoch 435/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2585 \n",
      "Epoch 436/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2569 \n",
      "Epoch 437/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2552 \n",
      "Epoch 438/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2564 \n",
      "Epoch 439/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2561 \n",
      "Epoch 440/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2567 \n",
      "Epoch 441/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2593 \n",
      "Epoch 442/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2543 \n",
      "Epoch 443/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2564 \n",
      "Epoch 444/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2533 \n",
      "Epoch 445/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2598 \n",
      "Epoch 446/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2567 \n",
      "Epoch 447/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2548 \n",
      "Epoch 448/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2608 \n",
      "Epoch 449/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2569 \n",
      "Epoch 450/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2555 \n",
      "Epoch 451/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2567 \n",
      "Epoch 452/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2613 \n",
      "Epoch 453/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 454/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2509 \n",
      "Epoch 455/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2542 \n",
      "Epoch 456/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2569 \n",
      "Epoch 457/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2564 \n",
      "Epoch 458/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2537 \n",
      "Epoch 459/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2550 \n",
      "Epoch 460/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2592 \n",
      "Epoch 461/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 462/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2508 \n",
      "Epoch 463/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2538 \n",
      "Epoch 464/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2556 \n",
      "Epoch 465/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2580 \n",
      "Epoch 466/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2518 \n",
      "Epoch 467/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2544 \n",
      "Epoch 468/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 469/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2532 \n",
      "Epoch 470/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 471/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2593 \n",
      "Epoch 472/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2522 \n",
      "Epoch 473/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2575 \n",
      "Epoch 474/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2585 \n",
      "Epoch 475/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2577 \n",
      "Epoch 476/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2530 \n",
      "Epoch 477/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2586 \n",
      "Epoch 478/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2526 \n",
      "Epoch 479/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2535 \n",
      "Epoch 480/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2589 \n",
      "Epoch 481/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2555 \n",
      "Epoch 482/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2570 \n",
      "Epoch 483/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2492 \n",
      "Epoch 484/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2606 \n",
      "Epoch 485/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2609 \n",
      "Epoch 486/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2583 \n",
      "Epoch 487/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2587 \n",
      "Epoch 488/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2559 \n",
      "Epoch 489/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2571 \n",
      "Epoch 490/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2599 \n",
      "Epoch 491/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2576 \n",
      "Epoch 492/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2552 \n",
      "Epoch 493/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2592 \n",
      "Epoch 494/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2559 \n",
      "Epoch 495/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2582 \n",
      "Epoch 496/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2588 \n",
      "Epoch 497/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2596 \n",
      "Epoch 498/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2588 \n",
      "Epoch 499/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2548 \n",
      "Epoch 500/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2609 \n",
      "Epoch 501/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2513 \n",
      "Epoch 502/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2542 \n",
      "Epoch 503/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2598 \n",
      "Epoch 504/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2568 \n",
      "Epoch 505/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2595 \n",
      "Epoch 506/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2597 \n",
      "Epoch 507/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2572 \n",
      "Epoch 508/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2561 \n",
      "Epoch 509/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2557 \n",
      "Epoch 510/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2573 \n",
      "Epoch 511/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2548 \n",
      "Epoch 512/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2593 \n",
      "Epoch 513/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2570 \n",
      "Epoch 514/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2578 \n",
      "Epoch 515/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2532 \n",
      "Epoch 516/10000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2542 \n",
      "Epoch 517/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mpredict(X))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:322\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m--> 322\u001b[0m         \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    324\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    325\u001b[0m             step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    326\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\callbacks\\callback_list.py:99\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_begin\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m     97\u001b[0m         callback\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, logs)\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_begin\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    100\u001b[0m     logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model.fit(X, y, batch_size = 1, epochs = 10000)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스를 사용하는 3가지 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m88\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m14\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466</span> (1.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466\u001b[0m (1.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466</span> (1.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m466\u001b[0m (1.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Sequential 모델을 만들고 모델에 필요한 레이어를 추가하는 방법\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, input_shape = (30,), activation = 'tanh'))\n",
    "model.add(Dense(8, activation = 'tanh'))\n",
    "model.add(Dense(6, activation = 'tanh'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(Adam(learning_rate = 0.04), 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m88\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m14\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466</span> (1.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m466\u001b[0m (1.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">466</span> (1.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m466\u001b[0m (1.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2) 함수형 API를 사용하는 방법\n",
    "\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "\n",
    "inputs = Input(shape = (30, ))\n",
    "layer0 = Dense(10, activation = \"tanh\")(inputs)\n",
    "layer1 = Dense(8, activation = \"tanh\")(layer0)\n",
    "layer2 = Dense(6, activation = \"tanh\")(layer1)\n",
    "prediction = Dense(2, activation = \"softmax\")(layer2)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = prediction)\n",
    "\n",
    "model.compile(Adam(learning_rate = 0.04), 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mlp\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) Model 클래스 상속하기\n",
    "\n",
    "class SimpleMLP(Model) :\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super(SimpleMLP, self).__init__(name = 'mlp')\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.dense1 = Dense(32, activation = 'sigmoid')\n",
    "        self.dense2 = Dense(num_classes, activation = 'sigmoid')\n",
    "\n",
    "    def call(self, inputs) :\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "model = SimpleMLP()\n",
    "\n",
    "model.compile(Adam(learning_rate = 0.04), 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스를 이용한 MNIST 숫자 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 데이터 가져오기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x130f54e9b20>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0], cmap = \"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\황주신\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 신경망 모델 구축하기\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu', input_shape = (784, )))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "train_images = train_images.reshape((60000, 784))\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "\n",
    "test_images = test_images.reshape((10000, 784))\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1125 - loss: 0.0900\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1094 - loss: 0.0900\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1122 - loss: 0.0900\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1108 - loss: 0.0900\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1115 - loss: 0.0900\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1160 - loss: 0.0900\n",
      "테스트 정확도 :  0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "model.fit(train_images, train_labels, epochs = 5, batch_size = 128)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('테스트 정확도 : ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1098 - loss: 0.0900\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1147 - loss: 0.0900\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1122 - loss: 0.0900\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1125 - loss: 0.0900\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1121 - loss: 0.0900\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "history = model.fit(train_images, train_labels, epochs = 5, batch_size = 128)\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label = 'Training Loss')\n",
    "plt.plot(epochs, acc, 'r', label = 'Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss/acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트하기\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('test.png', cv.IMREAD_GRAYSCALE)\n",
    "image = cv.resize(image, (28, 28))\n",
    "image = image.astype('float32')\n",
    "image = image.reshape(1, 784)\n",
    "image = 255 - image\n",
    "image /= 255.0\n",
    "\n",
    "plt.imshow(image.reshape(28, 28), cmap = 'Greys')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
